
---
subtitle: "TMA4268 Statistical Learning V2019"
title: "Compulsory exercise 3"
author: "Sara Elise Wøllo)"
date: "19 4 2020"
output: 
 # html_document
  pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3)
```

```{r rpackages,eval=TRUE,echo=FALSE}
# install.packages("knitr") #probably already installed
# install.packages("rmarkdown") #probably already installed
# install.packages("ggplot2") #plotting with ggplot
# install.packages("ggfortify")  
# install.packages("MASS")  
# install.packages("dplyr")  
# install.packages("keras")
#install.packages("pls")
# install.packages("gam")
# install.packages("tree")
# install.packages("randomForest")
library(knitr)
library(rmarkdown)
library(ggplot2)
library(ggfortify)
library(MASS)
library(dplyr)
library(GGally)
library(ggplot2)
library(ISLR)
library(keras)
#install_keras()
library(glmnet)
library(pls)
library(gam)
library(tree)
library(randomForest)
```



# Problem 1

## a)
```{r}

set.seed(1)

College$Private = as.numeric(College$Private)
train.ind = sample(1:nrow(College), 0.5 * nrow(College))
college.train = College[train.ind, ]
college.test = College[-train.ind, ]


college.train.pr=college.train
college.test.pr=college.test
college.train.pr$Outstate = NULL #Removing the Outstate column, it will be used in y_train
college.test.pr$Outstate = NULL #Removing the Outstate column, it will be used in y_test

mean <- apply(college.train.pr, 2, mean)
std <- apply(college.train.pr, 2, sd)
college.train.data <- scale(college.train.pr, center = mean, scale = std)
college.test.data <- scale(college.test.pr, center = mean, scale = std)


#Divide into redictors and response
x_train = college.train.data
x_test = college.test.data

y_train=college.train$Outstate
y_test=college.test$Outstate
```





## b)
$$
y_1 =\beta_{01} + \sum_{m=1}^{64} \beta_{m1} max \Big( \gamma_{0m}\sum_{l=1}^{64} \gamma_{lm} max \Big( \alpha_{0l}\sum_{j=1}^{17}\alpha_{jl}x_j,0 \Big),0\Big) 
$$


Using linear activation on the output layer.
## c)

```{r}

#Making the model
model <- keras_model_sequential() 
model %>% layer_dense(units = 64, activation = "relu", 
                        input_shape = c(17)) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 1, activation = "linear")
summary(model)

model %>% compile(optimizer = "rmsprop", loss = "mse", metrics = c("accuracy"))

history = model %>% fit(x_train, y_train, epochs = 300, batch_size = 8,
validation_split = 0.2)
```
```{r}
score=model %>% evaluate(x_test, y_test)
score
```




KODEEKS: 

```{r}
college.train.pred=college.train
college.test.pred=college.test
college.train.pred$Outstate <- NULL #Removing the Outstate column, it will be used in y_train
college.test.pred$Outstate <- NULL #Removing the Outstate column, it will be used in y_test
mean <- apply(college.train.pred, 2, mean)
std <- apply(college.train.pred, 2, sd)
train_data <- (scale(college.train.pred, center = mean, scale = std))
test_data <- (scale(college.test.pred, center = mean, scale = std))

#Splitting into predictors and response
x_train=train_data
x_test=test_data

y_train=college.train$Outstate
y_test=college.test$Outstate

# reshape, might not be necessary
x_train <- array_reshape(x_train, c(nrow(x_train), 17))
x_test <- array_reshape(x_test, c(nrow(x_test), 17))

# rescale response into one-hot
#y_train <- one_hot(y_train)
#y_train <- to_categorical(y_train)

#Making the model
model <- keras_model_sequential() 
model %>% layer_dense(units = 64, activation = "relu", 
                        input_shape = c(17)) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 1, activation = "linear")
summary(model)

model %>% compile(optimizer = "rmsprop", loss = "mse", metrics = c("accuracy"))

history = model %>% fit(x_train, y_train, epochs = 300, batch_size = 8,
validation_split = 0.2)
```


## d)



# Problem 2

```{r}
id <- "1CA1RPRYqU9oTIaHfSroitnWrI6WpUeBw"  # google file ID
d.corona <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", 
    id), header = T)
```



## a)
```{r}
count(d.corona, country, deceased)
count(d.corona, sex, deceased)
count(d.corona, country, sex, deceased)


```
We see that there are 14 (5 female (f), 9 male (m)) deceased in France, 2 (1 (f), 1 (m)) in Indonesia, 3 (0 (f), 3 (m)) in Japan and 26 ( 8(f), 18 (m)) in Korea. 
There are 14 females deceased and 31 males deceased. 



## b) 
Kan (kanskje) løse den brute force, men det er lite elegant. 
```{r, fig.width = 8, fig.asp = 1}

fit <-glm(deceased~sex + age + country, data = d.corona, family = "binomial")
fit

ggplot(data = d.corona, aes(age, deceased)) + geom_point()

summary(fit)

```

i) False? It is split into several covaraiates in the model ii) False? Don't need to remove from model even though it is not sig. iii) True iv) True

:::iii) Odds ratio
```{r}
eta = -7.633051 + (1.137246*1) + (0.068012*31) -(0.754259*0) -(2.434101*1) - (1.366797*0)  


newdata = exp(eta)/(1 + exp(eta))
newdata

odds = newdata / (1-newdata)
odds


```



## c)

```{r, fig.width = 6, fig.asp = 1}
grid_fr_m = expand.grid(sex="male",age= seq(20,100,1) ,country="France")
grid_fr_f = expand.grid(sex="female",age= seq(20,100,1) ,country="France")
grid_in_m = expand.grid(sex="male",age= seq(20,100,1) ,country="indonesia")
grid_in_f = expand.grid(sex="female",age= seq(20,100,1) ,country="indonesia")
grid_ja_m = expand.grid(sex="male",age= seq(20,100,1) ,country="japan")
grid_ja_f = expand.grid(sex="female",age= seq(20,100,1) ,country="japan")
grid_ko_m = expand.grid(sex="male",age= seq(20,100,1) ,country="Korea")
grid_ko_f = expand.grid(sex="female",age= seq(20,100,1) ,country="Korea")

m_france = predict.glm(fit, newdata = grid_fr_m, type = "response")
f_france = predict.glm(fit, newdata = grid_fr_f, type = "response")
m_indo = predict.glm(fit, newdata = grid_in_m, type = "response")
f_indo = predict.glm(fit, newdata = grid_in_f, type = "response")
m_japan = predict.glm(fit, newdata = grid_ja_m, type = "response")
f_japan = predict.glm(fit, newdata = grid_ja_f, type = "response")
m_korea = predict.glm(fit, newdata = grid_ko_m, type = "response")
f_korea = predict.glm(fit, newdata = grid_ko_f, type = "response")
```


```{r, fig.width = 6, fig.asp = 1}
plot(m_france, type = "l", lwd = 1, col = 1, xlab="Age", ylab="Probability of death")
lines(f_france, lwd = 1, col = 2)
lines(m_indo, lwd = 1, col = 3)
lines(f_indo, lwd = 1, col = 4)
lines(m_japan, lwd = 1, col = 5)
lines(f_japan, lwd = 1, col = 6)
lines(m_korea, lwd = 1, col = 7)
lines(f_korea, lwd = 1, col = 8)
title("Probability to die of Coronavirus, for country and sex")
legend(x = "topleft",legend = c("France,m","France,f", "Indonesia,m", "Indonesia,f", "Japan,m", "Japan,f", "Korea,m", "Korea,f"), lwd=c(2,2,2,2,2,2,2,2), col=c(1,2,3,4,5,6,7,8), y.intersp=1)


```

## d) [should I fit one more model?]
i) True. As you see from the plot "Probability to die of Coronavirus, for sex". Add \ref{}. Males have higher probability of death. 
ii) Yes? At a low age, the mortality rates are similar, but at age increases, the mortality rates increases faster for men than for women. 
iii) Yes? The mortality rate for the Frence population is higher even at low ages, but the difference increases as age increaces. 

```{r, fig.width=5, fig.height=5}
fit <-glm(deceased~sex + age, data = d.corona, family = "binomial")
fit

fit_country <- glm(deceased~ age + country, data = d.corona, family = "binomial")

grid_f = expand.grid(sex="female",age= seq(20,100,1))
grid_m = expand.grid(sex="male",age= seq(20,100,1))
f_pred = predict.glm(fit, newdata = grid_f, type = "response")
m_pred = predict.glm(fit, newdata = grid_m, type = "response")

grid_france = expand.grid(age= seq(20,100,1), country = "France")
grid_korea = expand.grid(age= seq(20,100,1), country = "Korea")
france_pred = predict.glm(fit_country, newdata = grid_france, type = "response")
korea_pred = predict.glm(fit_country, newdata = grid_korea, type = "response")
```


```{r, fig.width=5, fig.height=5}
plot(f_pred, type = "l", lwd = 1, col = 1, xlab="Age", ylab="Probability of death", xlim = c(0,90), ylim = c(0,0.5))
lines(m_pred, lwd = 1, col = 2)
lines(france_pred, lwd = 1, col = 3)
lines(korea_pred, lwd = 1, col = 4)

title("Probability to die of Coronavirus")
legend(x = "topleft",legend = c("Female","Male", "France", "Korea"), lwd=c(2,2,2,2), col=c(1,2,3,4), y.intersp=1)


```

## e)

Without knowing how the data was collected, this is not a result we can trust. We don't know how many were tested, and how sick people needed to be to be tested. If France only tested the people that were hospitalized, and the other countries tested more people with milder symptons, then it makes sense for France to have a higher mortality rate. 

## f)
i) True ii) True iii) True? (sometimes it is more important that ppl that deafault loans are predicted to default, than that people who don't default are predicted to not default. men her sa stefanie at de er vektet likt)  iv) False?? Not sure, might be useful. The error rate is not that high?



# Problem 3
```{r}
id <- "1heRtzi8vBoBGMaM2-ivBQI5Ki3HgJTmO"  # google file ID
d.support <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",
    id), header = T)
# We only look at complete cases
d.support <- d.support[complete.cases(d.support), ]
d.support <- d.support[d.support$totcst > 0, ]

```



## a)
```{r}
hist(d.support$totcst,plot=TRUE, main = "Total cost")
hist(d.support$age,plot=TRUE, main = "Age of patient")
hist(d.support$num.co,plot=TRUE, main = "No. of co-morbidities")
hist(d.support$edu,plot=TRUE, main = "Years of education")
hist(d.support$scoma,plot=TRUE, main = "Measure fo Glasgow coma scale")
hist(d.support$meanbp,plot=TRUE, main = "Mean blood pressure")
hist(d.support$hrt,plot=TRUE, main = "Heart rate")
hist(d.support$resp,plot=TRUE, main = "Respatory frequency")
hist(d.support$temp,plot=TRUE, main = "Body temperature")
hist(d.support$pafi,plot=TRUE, main = "Pa02/Fi02 proportion")
```
I suggest a logarithmic transformation to the variable totcst, histogram seen here:
```{r}
hist(log(d.support$totcst),plot=TRUE, main = "Log of total cost")
#From now, we use the transformed version of totcst
d.support$totcst = log(d.support$totcst)

```

## b)

```{r}
fit = glm(totcst~age+temp+edu+resp+num.co+dzgroup, data = d.support)
summary(fit)
```

```{r}
new_grid = expand.grid(age=c(10,20,30,40,50,60,70,80,90),temp= 36 ,edu = 10,resp = 20, num.co = 2, dzgroup = "CHF")

log_cost = predict.glm(fit,newdata = new_grid, type = "response")
cost = exp(log_cost)
cost
```
i) When a patient's age increases by 10 years, the cost increase by factor 0.93244 (or equivalently, decrease by factor 1.07245).

ii) 

```{r}
plot(fit)
```
We see from the Q-Q-diagram that the distibrution is normal, and not skewed. We see from the residuals vs. fitted-plot that there is no clear pattern, indicating that the assumptions in the model are fulfilled.

iii) 

## c)

```{r}
set.seed(12345)
train.ind = sample(1:nrow(d.support), 0.8 * nrow(d.support))
d.support.train = d.support[train.ind, ]
d.support.test = d.support[-train.ind, ]



```


```{r}
set.seed(12345)

lambdas <- 10^seq(2, -3, by = -.1)

x_train <- model.matrix(totcst~ .,data=d.support.train)
y_train <- d.support.train$totcst

ridge_mod <- glmnet(x_train,y_train ,family="gaussian", alpha = 0)
cv.out <- cv.glmnet(x_train, y_train, aplha = 0)
plot(cv.out)
lambda_1se <- cv.out$lambda.1se
```
The largest value of lambda such that the eror is within 1 std.error of the smallest lambda is 315.80.

```{r}
x_test <- model.matrix(totcst~ .,data=d.support.test)
y_test <- d.support.test$totcst

ridge_pred <-predict(ridge_mod, s = lambda_1se, newx = x_test)
mse_ridge <- mean(as.numeric((ridge_pred-y_test)^2))
mse_ridge
```
The test MSE of the ridge regression using lambda = 315.80 is 0.8636056.

## d)
i)

```{r}
set.seed(1)
pls_mod <- plsr(totcst~., data = d.support.train, scale = TRUE, validation = "CV")

```

```{r}
validationplot(pls_mod, val.type = "MSEP")
MSEP(pls_mod)
selectNcomp(pls_mod, method = "onesigma")
```


From the standard error of the CV residuals, we find that the best no. of componenets is 3. 

iii) 

```{r}
pls_pred = predict(pls_mod, d.support.test, ncomp=3)
head(pls_pred)
pls_sq_err <- as.numeric((pls_pred-d.support.test$totcst)^2)
mse_pls = mean(pls_sq_err)
mse_pls
```
The MSE of the test set when using 3 PCs are 0.86644. 

```{r}
mse_ridge
mse_pls
```
The MSE is similar, but the MSE from PLS is slightly higher. One is not significantly better than the other.  
## e)

i) 
```{r, height = 5, width = 5}
fitgam = gam(totcst ~ bs(age, knots = c(40,60,80)) + poly(num.co, 3) + s(edu, df = 5) + income + race + s(meanbp, df = 5) +s(hrt, df = 5) + bs(resp, knots = c(20)) + bs(temp, knots = c(35,37,38)) + poly(pafi, 2) + bs(scoma, knots = c(10,30))  + dzgroup, data = d.support.train)

# plot covariates
par(mfrow = c(2, 3))
plot(fitgam, se = TRUE, col = "blue")
# summary of fitted model
summary(fitgam)

gam_pred = predict(fitgam, d.support.test)
head(gam_pred)
gam_sq_err <- as.numeric((gam_pred-d.support.test$totcst)^2)
mse_gam = mean(gam_sq_err)
mse_gam

```
The choices of which transformation of the covariates was chosen, were done by plotting the different covariates and finding a suitable transfomation, depending on the spread of the data. Also, I spent some time trying out how the different transformations affected the different covariates. 




ii)



```{r}
#Bagging with random forest
set.seed(1)
oob.err = double(13)
mse_bag = double(13)
ntree = 350
for(mtry in 1:13){
  fit = randomForest(totcst~., data = d.support.train, mtry=mtry, ntree = ntree, importance = TRUE)
  oob.err[mtry] = fit$mse[ntree]
  pred = predict(fit, d.support.test)
  mse_bag[mtry] = with(d.support.test, mean((d.support.test$totcst-pred)^2 ))
}
min(mse_bag)
```
Using bagging, we find that the MSE is 0.8232. 

This is the mest model fitted in this exercise. Bagging is suitable for regression tree problems like this is. I did this because the result from a standard regression tree was too poor. 



# Problem 4

## a)

Basis functions: 
$$
b_1(x) = X \text{, } b_2(x) = X^2 \text{, } b_3(x) = X^3 \text{, } b_4(x) = (X-1)_+^3 \text{, } b_5(x) = (X-2)_+^3.

$$
Design matrix: Usikker på hvordan jeg skal gjøre det... Skal det være en nxp-matrise, skal det være subskript på x-ene? Skal jeg bruke bs()? tror jeg skal skrive for hånd.. 
$$

\begin{bmatrix}
1 & x_1 & x_1^2 & x_1^3 & (x_1-1)_+^3 & (x_1-2)_+^3 \\
1 & x_2 & x_2^2 & x_2^3 & (x_2-1)_+^3 & (x_2-2)_+^3 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
1 & x_n & x_n^2 & x_n^3 & (x_n-1)_+^3 & (x_n-2)_+^3 \\
\end{bmatrix}

$$

## b)
i) True ii) True iii) True iv) False

## c)

i) False ii) False iii) False? (too small difference r) iv) False

# Problem 5

## a)
 i) True, ii) True, iii) False, iv) Unsure (You can use reg, but is it a method for reg?)

## b)
i) False ii) True iii)  False iv) True?

## c) Single choice

True: iv) 

## d) Single choice

True: ii) 

## e) Single choice
True: iv) 

## f)
i) True ii) False ? (can happen, but not always true. as sensitivity increases, specificity doesn't HAVE to go down)  iii)  False iv) True

## g)
i) False  ii) True iii) True  iv) True
